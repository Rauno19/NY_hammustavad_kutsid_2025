1. Extract and transform the source data:
    Pull in the selected data source(s) and preprocess the data as needed.
   **Tuleb puhastada csv-st väljadelt AGE ära täht Month(M või Y vm)**
   **TEHTUD** - vanus on nüüd aastates, ümardatud 2 kohta peale koma
    Perform data transformation and cleaning tasks to ensure data consistency and accuracy.
   
3. Load the transformed data:
    Load the cleaned and transformed data into an SQL or flat database.
    Ensure proper indexing and organization of the data for efficient querying and analysis.
   
5. Create a data visualization:
    Using Apache Superset, Tableau, R ggplot (RMarkdown), or Python plotnine, create a compelling visualization that highlights key insights and tells a story with the data.
    Ensure that the visualization is clear, concise, and visually appealing.
   
7. Focus on data management and data engineering aspects:
    Ensure that your project follows the best data management and engineering practices.
    Use a shared git repository for version control and collaboration among group members.
    Maintain an up-to-date README that documents the project progress and provides a clear overview of the project structure.
    Provide detailed documentation on how to use the pipeline from start to finish, including any prerequisites, installation steps, and instructions for running the ETL process and generating the visualization.
   
